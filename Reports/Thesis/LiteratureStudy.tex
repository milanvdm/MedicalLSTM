\graphicspath{ {LiteratureStudyImages/} }


\chapter{Literature Study}
\label{cha:literatureStudy}

\section{Introduction}
In this chapter 


\section{Background Knowledge}
We assume a basic knowledge of general computer science concepts as algorithms, statistics, time complexity, linear algebra, basic graph theory, optimization, and heuristics.


	\subsection{Machine Learning}
Machine learning is a data driven approach with as goal to build a model which can be	used to make predictions or decisions. This task is done by algorithms which are able to learn models based on examples given by the designer. In machine learning there are $3$ types of problems, namely supervised learning, unsupervised learning, and reinforcement learning. \\
Supervised learning is concerned with the learning task where there are examples given with their corresponding label. Unsupervised learning is similar to supervised learning only no labels are given. We won't go into reinforcement learning. \\
We can also classify to problems according to the desired output of our model. Those main tasks consist of classification, regression, clustering, and dimension reduction.
	
	
	\subsection{Time Series Analysis}
A time series consists of data points over a certain time period. We refer to this as a sequence of states. Where a state represents a data point and can differ from a single value to more complex representations like pictures. \\
The domain of time series analysis handles around extracting information or relations from a time series. It can have different goals like forecasting, classification, or exploratory.
	
	
	\subsection{Neural Networks}
	
A neural network is a machine learning approach based on biological neural networks. 


		\subsubsection{Perceptron}

The basic component of a neural network is a perceptron. A perceptron take multiple binary inputs and has a single binary output (see figure \ref{fig:perceptron}). Each input has a corresponding real numbered weight. The output is decided on the following equation:

\begin{equation} 
output =
  \begin{cases}
    0       	& \quad \text{if } \sum_j w_jx_j \leq \text{ threshold}\\
    1  		& \quad \text{if } \text{if } \sum_j w_jx_j > \text{ threshold}\\
  \end{cases}
\end{equation}
	
\begin{figure}[H]
	\centering
	\includegraphics[width=4cm]{perceptron.png}
	\caption{A simple presentation of a perceptron.}
	\label{fig:perceptron}
\end{figure}

We can build a network by connecting multiple perceptrons (see figure \ref{fig:multiplePerceptrons}. By building these networks, more complex decisions can be made.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{multiplePerceptrons.png}
	\caption{A more complex network made by connecting multiple perceptrons.}
	\label{fig:multiplePerceptrons}
\end{figure}

Now we have seen how a general network is constructed, we look at some vocabulary. \\
In figure \ref{fig:networkArch}, we see a four-layer network. As mentioned on the figure, we call the first layer the input layer, the last layer the output layer, and the layers in between are called hidden layers. Sometime multiple layer networks are referred to as multilayer perceptrons or MLPs.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{networkArchitecture.png}
	\caption{General vocabulary for a multilayer network.}
	\label{fig:networkArch}
\end{figure} 		


		\subsubsection{Training a network}
		
To train a neural network, we input an example with a known label. The network will have a certain output based on the current weights. When this output is incorrect, it should be possible to adjust the weights with as effect that the network now has as output the correct label. Of course, this change in weights, should only effect the output by a small bit (see figure \ref{fig:smallChange}). The reason for this is that otherwise all the previous images could now be labeled incorrectly. So, the concept of training a neural network means, adjusting the weights in a way that the behavior of the network doesn't change completely on the previous seen pictures but that the current picture is labeled correctly.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{smallChange.png}
	\caption{A small change on the weights, only has a small impact on the output.}
	\label{fig:smallChange}
\end{figure} 

To achieve this effect, we change our known perceptrons to sigmoid neurons. A sigmoid neuron has the same basics as a perceptron. It still has inputs but now it also has a bias $b$. The inputs still have weights but the weights can now range between $0$ and $1$. The output is now calculate with $\sigma(w*x+b)$ where $\sigma$ is the sigmoid function. This results in the following formula: 

\begin{equation} 
\frac{1}{1+exp(-\sum_j w_jx_j-b)}
\end{equation}

The sigmoid function makes it possible to calculate the gradient and makes the output a linear combination of $\Delta w_j$ and $\Delta b$ as $\Delta output$ is approximated by 

\begin{equation} 
\Delta output \approx \sum_j \frac{\partial output}{\partial w_j}\Delta w_j + \frac{\partial output}{\partial b}\Delta b
\end{equation}

Because of the linearity, it is now possible to choose changes for the weights and biases to achieve a correct output. By adjusting the weights, we will train our network to achieve a higher accuracy.
		
	\subsection{Backpropagation}
	
Backpropagation is an algorithm which is used to train neural networks. It calculates the gradient of a chosen loss function with respect to the individual weights. With the gradient, the weights are updated and the loss function is minimized.

		\subsubsection{Terminology}
		
We use $w^l_{jk}$ to denote the weight corresponding to the connection between the $k^{th}$ node in the $(l-1)^{th}$ layer to the $j^{th}$ node in the $l^{th}$ layer. We use $b^l_j$ for the bias of the $j^{th}$ node in the $l^{th}$ layer and $a^l_j$ for the activation of the $j^{th}$ node in the $l^{th}$ layer. See figure \ref{fig:termNN}.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{termNN.png}
	\caption{Visual representation of the terminology for a neural network.}
	\label{fig:termNN}
\end{figure} 

We can now convert these notation to a vector representation. We remove the indexes for the node numbers which results in the following:

\begin{equation} 
a^l = \sigma (w^la^{l-1}+b^l)
\end{equation}

		\subsubsection{Cost function}
		
AS mentioned before, backpropagation has as goal to calculate the partial derivatives of the cost function $C$ with respect to each weight and bias. \\
The cost function has to fulfill certain criteria. The first one is that it needs to be possible to write it as a summation over cost functions for individual training examples. Secondly, it needs to be derivable. And lastly, the cost function is a function of the activations of the last layer. 


		\subsubsection{Fundamental equations}

Backpropagation has 4 equations. They allow us to calculate the error for each node and adjust the weights based on the gradient descent. \\

First we calculate the error of each node which is based on how much the cost function is influenced by each activation and on how much the activation function is influenced by $z_j^L$:

\begin{equation} 
\delta^L_j = \frac{\partial C}{\partial a^L_j} \sigma'(z_j^L)
\text{ with }
z_j^L = \sum_k w^L_{jk}a^{L-1}_k+b^L_j
\end{equation}

This can be written as a neat vector equation:

\begin{equation} 
\delta^L = (a^L-y) \circ \sigma'(z_j^L)
\end{equation}

The next equation explains why the algorithm is called backpropagation. The equation calculates each layers error vector based on the layer after it, it propagates the error back over the layers:

\begin{equation} 
\delta^l = ((w^{l+1})^T\delta^{l+1}) \circ \sigma'(z_j^L)
\end{equation}

With those 2 equations we calculate the error in each layer in the neural network. Those errors can be used to calculate the derivatives of the cost function with respect to the weights and the biases:

\begin{equation} 
\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j.
\end{equation}

\begin{equation} 
\frac{\partial C}{\partial b^l_j} = \delta^l_j.
\end{equation}

When the derivatives are calculated, we can apply the gradient descent and update the weights and biases accordingly. This process represents the learning of a neural network.



http://neuralnetworksanddeeplearning.com/chap1.html


\section{Disease Progression}

\section{Word2Vec}


\section{Tsne projection}

\section{Vantage Point Tree}

\section{DeepWalk}


\section{Conclusion}
The final section of the chapter gives an overview of the important results
of this chapter. This implies that the introductory chapter and the
concluding chapter don't need a conclusion.



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
